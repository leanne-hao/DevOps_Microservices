C:\WINDOWS\system32>kubectl run udacityai --image=leannehao/udacityaiengeer:v0.2 --port=80 -it
If you don't see a command prompt, try pressing enter.
starting app...
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
starting app...
 * Debugger is active!
 * Debugger PIN: 894-679-157
[2020-12-27 09:14:42,026] INFO in app: JSON payload:
{'CHAS': {'0': 0}, 'RM': {'0': 6.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2020-12-27 09:14:42,045] INFO in app: Inference payload DataFrame:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2020-12-27 09:14:42,058] INFO in app: Scaling Payload:
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2020-12-27 09:14:42,064] INFO in app: Prediction value:
[20.35373177134412]
127.0.0.1 - - [27/Dec/2020 09:14:42] "POST /predict HTTP/1.1" 200 -


C:\WINDOWS\system32>kubectl get pods
NAME        READY   STATUS    RESTARTS   AGE
udacityai   1/1     Running   0          52s

C:\WINDOWS\system32>kubectl expose pod udacityai --type=LoadBalancer --port=8000 --target-port=80
service/udacityai exposed

C:\WINDOWS\system32>kubectl port-forward service/udacityai 8000
Forwarding from 127.0.0.1:8000 -> 80
Forwarding from [::1]:8000 -> 80
Handling connection for 8000